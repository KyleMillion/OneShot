# Patriot Equipment Rentals – Competitor Price-Gap Tool

## Comprehensive Project Assessment & Wiring Analysis

_This report was generated by the Cursor.AI Agent on {{DATE}}. It analyses the project in its current local state and cross-references it against the original design intent described in `OneShotRef.jsonc` and `INITIAL_VENDOR_TARGET_DATA.md`._

---

### 1. Overall Project Structure & Root Configurations

**File-system validation**
* Root and `packages/` directory hierarchy matches the schema from `OneShotRef.jsonc` with six workspaces (`shared-types`, `crawler`, `scraper`, `etl`, `analytics`, `report`).
* Missing artefacts compared with Phase-1 spec:
  * `.env.example` – **absent**.
  * `.nvmrc`, `.gitignore` – **absent**.
  * `.github/workflows/ci.yml` – **absent** (CI pipeline not set up).
  * `AI_CONFIG_INVESTIGATION_REPORT.md` – referenced in directives but **not found**.

**Root `package.json`**
✓ All prescribed scripts exist (`generate-report`, `db:up`, etc.).  
✓ Dev-dependencies match versions in spec.

**Root `tsconfig.json`**
✓ `strict: true`, ES2022 target & commonjs module as required.

**`docker-compose.yml`**
✓ All six services (Postgres, Redis, Weaviate, Browserless, FlareSolverr, Temporal) present with correct images and env placeholders.

**Config directory**
✓ `patriot_catalog_config.json`, `patriot_catalog.csv`, `initial_competitors_to_process.json` all present and structurally correct.

---

### 2. Vendor Scraper Configurations (`packages/scraper/src/configs/`)

| Vendor | Regex status | Selector status | Notes |
|--------|--------------|-----------------|-------|
| sunbelt | Present – blueprint value | Placeholders with guidance; need human verification | Uses `useFlaresolverr: true` |
| unitedrentals | Present – blueprint value | Placeholders | Lacks sitemap `startUrl`; operator action comment present |
| fabickrents | Present | Placeholders | |
| mikesrentals | Present | Placeholders | |
| farmingtonrentalstore | Present | Placeholders | |
| patriot | Regex & startUrls are **placeholders** | ALL selectors flagged "CRITICAL" placeholders | Must be fully defined by operator |

Common findings:
* Fields `ISPRODUCTPAGECHECKER_PLACEHOLDER`, `NETWORKINTERCEPTS_PLACEHOLDER`, `CUSTOMPARSER_PLACEHOLDER` remain in every config ⇒ additional logic may still need to be inserted.
* No configs include validated CSS selectors; scraping will almost certainly fail until operator completes them.

---

### 3. Shared Types Package Integrity

* Interfaces `Price`, `RentalRates`, `RawScrapedProduct`, `NormalizedProduct`, `VendorConfig`, `PatriotCatalogItem`, `ReportGenerationOrchestratorInput` **exist and align** with spec.
* **Missing types**:
  * `RateParsingConfig` referenced by ETL `normalization.service.ts` is **not defined** in `shared-types`.
* **Schema drift**:
  * `RawScrapedProduct` in shared types does **not** contain fields `rawPriceDay`, `rawPriceWeek`, `rawPriceMonth`, `breadcrumbs`, etc., which are referenced in ETL normalization logic.

These mismatches will cause type-errors or runtime undefined values during ETL.

---

### 4. Core Pipeline Components

#### a. Crawler (`@patriot-rentals/crawler`)
* Implements `runCrawlers()`, loads proxy & FlareSolverr logic correctly.
* Utilises `PlaywrightCrawler` and enqueues product links; dispatches `scrapeProductWorkflow` via Temporal.
* **Hard-coded Temporal args mismatch** – passes single object `{url, vendorId, forceRescrape}` but workflow expects `(url: string, vendorId: string, forceRescrape?: boolean)`.
* Good error handling & logging.

#### b. Scraper (`@patriot-rentals/scraper`)
* Worker, workflow, and activity files present.
* `scrapeProductPageActivity` correctly pulls `VendorConfig`; supports network intercepts and debug snapshots.
* **Sunbelt modal/location handling** – _absent_; no special Playwright logic for opening modals or setting ZIP code.

#### c. ETL (`@patriot-rentals/etl`)
* Workflow & activity scaffolds exist; services for Postgres & Weaviate stubbed.
* `normalizeRawProductData` expects fields not emitted by scraper → will produce `undefined` prices.
* Table creation / SQL helpers mentioned in comments but actual SQL execution code is **not implemented**.

#### d. Analytics (Python)
* Matching, embedding, and reporting utils exist with decent stub logic.
* Requires proper DB schema & data to function; no unit tests.

#### e. Report Orchestrator
* CLI & orchestrator implemented; triggers crawler via Temporal and analytics via `execSync`.
* Wait/monitor logic for Temporal workflow completion **not implemented** – pipeline assumes downstream work will finish eventually.

---

### 5. Testing & Documentation

* Test directories exist but contain only placeholder stubs – **no executable tests**.
* Root `README.md` present and follows directive outline.
* Continuous-integration file **missing** – automated lint/typecheck/test on PRs not active.

---

## Overall Readiness & Critical Next Steps

**Readiness Summary**: The project is ~60% scaffolded. Core TypeScript plumbing (crawler, scraper, ETL, report orchestrator) exists, but critical configuration, typing, and database implementation gaps prevent end-to-end execution.

### Priority Fix List
1. Create `.env.example` and ensure all env vars referenced in code are covered.
2. Finalise `VendorConfig` files:
   * Verify/replace `productUrlDetectRegex` for each vendor.
   * Replace all CSS selector placeholders.
   * Implement any required `isProductPageChecker`, `networkIntercepts`, `customParser` logic.
3. Add missing shared types (`RateParsingConfig`, additional raw price fields) and reconcile `RawScrapedProduct` vs scraper output.
4. Implement database layer in ETL (`saveNormalizedProduct`, table DDL, Weaviate schema creation).
5. Address crawler→workflow parameter mismatch.
6. Implement Sunbelt/United modal logic for prices (location selection).
7. Implement monitoring/waiting in report orchestrator to ensure pipeline completion before analytics.
8. Write real unit/integration tests; set up `.github/workflows/ci.yml`.
9. Add `.gitignore`, `.nvmrc`, and generate `AI_CONFIG_INVESTIGATION_REPORT.md` for operator tracking.

### Confidence & Fragility Assessment
* **Inter-component wiring**: Temporal task-queue names correctly referenced; scraper→ETL child workflows coded, but lack of database schema and type mismatches will likely cause first-run failures.  
* **Fragility hotspots**: Vendor selectors, FlareSolverr dependency, normalization type drift, report orchestrator asynchronous assumptions.

**Confidence level**: ⭐⭐☆☆☆ (2/5) – substantial core logic exists, but multiple critical holes must be filled before a successful price-gap report can be generated. 